# Auto Face Pose Capture using Logistic Regression

## ðŸš€ Problem Statement

In our computer vision application, we wanted to **add a personâ€™s face data into a database** by capturing it from a camera. Typically, this requires capturing images from multiple facial angles manually â€” such as:
- Left profile
- Right profile
- Upward (top) view
- Downward (bottom) view
- Center (frontal) view

Manually clicking images while instructing a person to rotate their head is time-consuming and error-prone.

### ðŸŽ¯ Objective

**Automate the face pose capturing process** using machine learning. Once the camera starts, the model should automatically identify the current head position and capture the face when it matches any of the five desired directions.

---

## ðŸ§  ML Solution

To solve this, we used **InsightFace's face pose estimation** features â€” extracting 3 key pose parameters:
- `yaw`
- `roll`
- `pitch`

Using these, we created a dataset where each face image was labeled based on its pose direction. Then, we trained a **Logistic Regression model** using a total of **150 features** derived from the face landmarks and pose data.

---

## ðŸ“Š Model Training & Evaluation

- âœ… Model: **Logistic Regression**
- ðŸ“ˆ Accuracy: **~90%**
- ðŸ”¢ Features Used: **150 pose-related features**
- ðŸ§ª Evaluation: Based on test set performance and live camera testing.

---

## ðŸ“¦ Project Structure
``` 
 â”œâ”€â”€app
    â”œâ”€â”€ captured_face_sides/            # all captured face images
    â”œâ”€â”€ configs/        # all configuration
    â”œâ”€â”€ data/           # all data related scripts
    â”œâ”€â”€ models/      
    â”œâ”€â”€ src/               
    â”œâ”€â”€ ..
    â”œâ”€â”€ .. 
    â”œâ”€â”€ live.py
    â”œâ”€â”€ main.py
           
â””â”€â”€ README.md            # Project documentation
```


---

## ðŸŽ¥ Demo Video

Watch the project demo here: [Demo Video on YouTube](https://www.youtube.com/watch?v=YOUR_VIDEO_ID)


## ðŸŽ¥ Real-time Demo

Run the following to test the model on a live webcam feed:

```bash
git clone https://github.com/ak-123459/LookWhere.git
```

```bash
cd LookWhere
```

```bash
pip install -r requirements.txt
````


```bash
python app/live.py
```


### Train and validate the model

````
python app/main.py
````


## ðŸ§  Model
**Algorithm**: Logistic Regression

**Input**: Pose features (yaw, pitch, roll, etc.)

**Output**: Face direction label

## ðŸ“‚ Configuration
Hyperparameters and model configs can be found and edited in config.yaml.

## ðŸ“ƒ License
This project is licensed under the **MIT** License.




